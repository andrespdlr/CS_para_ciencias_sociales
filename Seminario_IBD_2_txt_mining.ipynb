{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Author: Manuel Aragones and Andr√©s Ponce de Leon Rosas\n",
    "Date: June 2017\n",
    "The following cheatsheet is entirely based on the \"Natural Language \n",
    "Processing with Python\" book from Steven Bird, Ewan Klein, \n",
    "and Edward Loper.\n",
    "This workshop is constructed for the IBD workshop and is based on the Text Mining for Public Policy course at UofC, the Advanced Machine Learning for Public Policy and the NLTK book.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To download the corpora\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similar words\n",
    "\"\"\"\n",
    "Look for similar words: \n",
    "<text>.similar(\"<word>\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Word context\n",
    "\"\"\"\n",
    "Examine the context shared by two or more words: \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ploting words ocurrence\n",
    "\"\"\"\n",
    "Plot the location of a word within a text: \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lenght of text\n",
    "\"\"\"\n",
    "Get the length of a variable:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set of unique wordss\n",
    "\"\"\"\n",
    "Get rid of duplicates:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lexical diversity\n",
    "\"\"\"\n",
    "Define a function that estimates the lexical diversity.\n",
    "By dividing unique words over total words we can create\n",
    "an indicator of the lexical richness:\n",
    "unique_words = len(set(<varname>))\n",
    "total_words = len(<varname>)\n",
    "rich_index = unique_words / total_words\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Word count & share\n",
    "\"\"\"\n",
    "Define a function that estimates the \"market\" share of a word\n",
    "Count or obtain share of the number of times a word appears \n",
    "in a text:\n",
    "word_count = <varname>.count(<\"word\">)\n",
    "word_share = <varname>.count(<\"word\">) / len(<varname>)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3 Computing with Language: Simple Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 3.1 Frequency Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Frequency distribution\n",
    "\"\"\"\n",
    "To obtain the frequency of the words contained in a particular text\n",
    "search for the NLTK function\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Most common words\n",
    "\"\"\"\n",
    "Print the n most common words using NLTK:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Count a specific word (alternative method)\n",
    "\"\"\"\n",
    "Obtain the number of appearances of a word :\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Plot cumulative distribution\n",
    "\"\"\"\n",
    "Plot a cumulative distribution of 'n' number of words\n",
    "\"\"\"\n",
    "\n",
    "# Words that repeat only once\n",
    "\"\"\"\n",
    "To obtain a list with words that appear only once in a text\n",
    "the .hapaxes() function in NLTK is useful:\n",
    "FreqDist(<varname>).hapaxes()\n",
    "\"\"\"\n",
    "FreqDist(text1).hapaxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.2 Fine-grained selection of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter words based on length and/or frequency\n",
    "\"\"\"\n",
    "Sometimes it is useful to filter words based on a specific \n",
    "length. To do so, we can use a loop that iterates through the\n",
    "original text and only adds a word to a new list if it is within\n",
    "the specified length.\n",
    "\"\"\"\n",
    "def word_filter(text, min_len, max_len, min_freq):\n",
    "    return l_filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Search\n",
    "\"\"\"\n",
    "Search function with context (concordance): \n",
    "<varname>.concordance(\"<word>\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.3 Bigrams and Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bigrams\n",
    "\"\"\"\n",
    "Use the bigrams function from nltk\n",
    "bigram: tuple of words, that is, word pairs\n",
    "list(bigrams(<list_with_text>))\n",
    "*it is important to specify the type == list to bigrams()\n",
    "\"\"\"\n",
    "\n",
    "from nltk import bigrams\n",
    "list1 = ['more', 'is', 'said', 'than', 'done']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collocations\n",
    "\"\"\"\n",
    "collocation: sequence of words that occur together unusually often\n",
    "<varname>.collocations()\n",
    "\"\"\"\n",
    "from nltk import collocations\n",
    "text2.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 3.4 Counting other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Frequency distribution of the length of words\n",
    "\"\"\"\n",
    "Obtain a dictionary with the length of a word as a key and\n",
    "the count of ocurrences the value, you can do the following:\n",
    "\"\"\"\n",
    "def FreqDist_of_length(text):\n",
    "    l_lengths = [len(w) for w in text]\n",
    "    return FreqDist(l_lengths)\n",
    "\n",
    "def SampleDescriptives(text):\n",
    "    \"\"\"propose a function that outputs descriptive stats\"\"\"\n",
    "    \n",
    "SampleDescriptives(text1)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Table 3.1 From NLTK Book\n",
    "\"\"\"\n",
    "create a frequency distribution containing the given samples\n",
    "fdist = FreqDist(samples)\n",
    "\n",
    "increment the count for this sample\n",
    "fdist[sample] += 1\n",
    "\n",
    "count of the number of times a given sample occurred\n",
    "fdist['monstrous']\n",
    "\n",
    "frequency of a given sample\n",
    "fdist.freq('monstrous')\n",
    "\n",
    "total number of samples\n",
    "fdist.N()\n",
    "\n",
    "the n most common samples and their frequencies\n",
    "fdist.most_common(n)\n",
    "\n",
    "iterate over the samples\n",
    "for sample in fdist:\n",
    "\n",
    "sample with the greatest count\n",
    "fdist.max()\n",
    "\n",
    "tabulate the frequency distribution\n",
    "fdist.tabulate()\n",
    "\n",
    "graphical plot of the frequency distribution\n",
    "fdist.plot()\n",
    "\n",
    "cumulative plot of the frequency distribution\n",
    "fdist.plot(cumulative=True)\n",
    "\n",
    "update fdist1 with counts from fdist2\n",
    "fdist1 |= fdist2\n",
    "\n",
    "test if samples in fdist1 occur less frequently than in fdist2\n",
    "fdist1 < fdist2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Back to Python: Making Decisions and Taking Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 4.1 Conditionals (Table 4.1)\n",
    "\"\"\"\n",
    "Operator and Relationship\n",
    "<    less than\n",
    "<=   less than or equal to\n",
    "==   equal to (note this is two \"=\" signs, not one)\n",
    "!=   not equal to\n",
    ">    greater than\n",
    ">=   greater than or equal to\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 4.2 Conditionals (Table 4.1)\n",
    "\"\"\"\n",
    "Function and Meaning\n",
    "s.startswith(t) test if s starts with t\n",
    "s.endswith(t)\ttest if s ends with t\n",
    "t in s\ttest if t is a substring of s\n",
    "s.islower()\ttest if s contains cased characters and all are lowercase\n",
    "s.isupper()\ttest if s contains cased characters and all are uppercase\n",
    "s.isalpha()\ttest if s is non-empty and all characters in s are alphabetic\n",
    "s.isalnum()\ttest if s is non-empty and all characters in s are alphanumeric\n",
    "s.isdigit()\ttest if s is non-empty and all characters in s are digits\n",
    "s.istitle()\ttest if s contains cased characters and is titlecased (i.e. all words in s have initial capitals)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "s = \"4\"\n",
    "print(s.islower(),\n",
    "      s.isalpha(),\n",
    "      s.istitle(),\n",
    "      s.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter words II\n",
    "\"\"\"\n",
    "Filter words based on the aforementioned conditions\n",
    "and other useful ones:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
